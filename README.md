# dockerized-etl-data-pipeline
End-to-end ETL data engineering pipeline using Python, Airflow, dbt, PostgreSQL, Superset, and Docker for containerized, reproducible analytics workflows.

Permissions (Linux/Mac only):
chmod +x postgres/*.sh docker/*.sh

Setup Instructions:
1. Clone the repo.

2. Run cp .env_example .env (or copy/rename manually).

3. Configure Docker Init Environment: cp docker/.env_example docker/.env

4. Configure .env files

5. Start Docker

5. Run docker-compose up.

